# Bias vs Variance

![BiasVSVariance](Images/biasVSvariance.png)

The goal of any **supervised machine learning algorithm** is to **best estimate** the **mapping function (f)** for the output variable (**Y**) given the input data (**X**). The mapping function is often called the **target function** because it is the function that a given supervised machine learning algorithm aims to approximate.

The prediction error for any machine learning algorithm can be broken down into three parts:

* **Bias Error**
* **Variance Error**
* **Irreducible Error**

## Irreducible Error

The irreducible error cannot be reduced regardless of what algorithm is used. It is the error introduced from the chosen framing of the problem and may be caused by factors like unknown variables that influence the mapping of the input variables to the output variable.

> Machine learning algorithms use mathematical or statistical models with inherent errors in two categories: **reducible** and **irreducible** error. **Irreducible error**, or **inherent uncertainty**, is due to natural variability within a system. In comparison, **reducible error** is more controllable and should be minimized to ensure higher accuracy.
>
> Irreducible error is the error that can’t be reduced by creating good models. It is a measure of the amount of **noise in our data**. Here it is important to understand that no matter how good we make our model, our data will have certain amount of noise or irreducible error that can not be removed.
>
> **Bias** and **variance** are components of **reducible error**.

## Bias Error

Bias are the **simplifying assumptions** made by a model to make the target function easier to learn.

> Bias is the difference between the average prediction of our model and the correct value which we are trying to predict. Model with **high bias** pays **very little attention** to the **training data** and **oversimplifies** the model. It always leads to high error on **training** and **testing** data.

Generally, **linear algorithms** have a **high bias** making them **fast to learn** and **easier to understand** but generally **less flexible**. In turn, they have lower predictive performance on complex problems that fail to meet the simplifying assumptions of the algorithms bias.

* **Low Bias**: Suggests **less assumptions** about the form of the target function.
* **High-Bias**: Suggests **more assumptions** about the form of the target function.
  
Examples of **low-bias machine learning algorithms** include: **Decision Trees**, **k-Nearest Neighbors** and **Support Vector Machines**.

Examples of **high-bias machine learning algorithms** include: **Linear Regression**, **Linear Discriminant Analysis** and **Logistic Regression**.

## Variance Error

Variance is the amount that the estimate of the target function will change if **different training data** was used.

> Model with **high variance** pays **a lot of attention** to **training data** and **does not generalize** on the data which it hasn’t seen before. As a result, such models perform very well on training data but has high error rates on test data.

The target function is estimated from the training data by a machine learning algorithm, so we should expect the algorithm to have some variance. Ideally, it should not change too much from one training dataset to the next, meaning that the algorithm is good at picking out the hidden underlying mapping between the inputs and the output variables.

Machine learning algorithms that have a **high variance** are **strongly influenced** by the **specifics** of the training data. This means that the specifics of the training have influences the number and types of parameters used to characterize the mapping function.

* **Low Variance**: Suggests small changes to the estimate of the target function with changes to the training dataset.
* **High Variance**: Suggests large changes to the estimate of the target function with changes to the training dataset.

Generally, **nonlinear machine learning algorithms** that have a lot of **flexibility** have a **high variance**. For example, **decision trees** have a high variance, that is even higher if the trees are not pruned before use.

Examples of **low-variance machine learning algorithms** include: **Linear Regression**, **Linear Discriminant Analysis** and **Logistic Regression**.

Examples of **high-variance machine learning algorithms** include: **Decision Trees**, **k-Nearest Neighbors** and **Support Vector Machines**.

## Bias-Variance Trade-Off

* If our model is **too simple and has very few parameters** then it may have **high bias** and **low variance**.
* On the other hand if our model has large number of **parameters** then it’s going to have **high variance** and **low bias**.

There is no escaping the relationship between bias and variance in machine learning.

* Increasing the bias will decrease the variance.
* Increasing the variance will decrease the bias.

So we need to find the right/good balance without overfitting and underfitting the data.

When building a supervised machine-learning algorithm, the goal is to achieve **low bias and variance** for the most accurate predictions. Data scientists must do this while keeping **underfitting** and **overfitting** in mind:

* A model that exhibits **small variance** and **high bias** will **underfit** the target
* A model with **high variance** and **little bias** will **overfit** the target.

A model with **high variance** may represent the data set accurately but could lead to **overfitting** to noisy or otherwise unrepresentative training data. In comparison, a model with **high bias** may **underfit** the training data due to a simpler model that overlooks regularities in the data.

The **trade-off challenge** depends on the **type** of model under consideration:

* A **linear** machine-learning algorithm will exhibit **high bias** but **low variance**.
* On the other hand, a **non-linear** algorithm will exhibit **low bias** but **high variance**.

Using a **linear model** with a **data set that is non-linear** will introduce **bias** into the model. The model will **underfit** the target functions compared to the training data set.

The reverse is true as well — if you use a **non-linear model** on a **linear dataset**, the non-linear model will **overfit** the target function.

There is always tension between bias and variance. In fact, it’s difficult to create a model that has both low bias and variance. The goal is a model that reflects the linearity of the training data but will also be sensitive to unseen data used for predictions or estimates. Data scientists must understand the difference between bias and variance so they can make the necessary compromises to build a model with acceptably accurate results.
